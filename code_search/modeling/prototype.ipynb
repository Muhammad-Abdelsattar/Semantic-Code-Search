{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/semantic_code_search/code_search/modeling\n"
     ]
    }
   ],
   "source": [
    "%cd semantic_code_search/code_search/modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from enum import Enum, auto\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Type\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, PreTrainedTokenizerBase,PreTrainedTokenizer\n",
    "from transformers.data import DataCollatorForSeq2Seq\n",
    "from peft import (PeftModel, PeftConfig, PrefixTuningConfig, \n",
    "                 LoraConfig, get_peft_model, TaskType)\n",
    "from tokenizers import Tokenizer\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Optional, Dict, Type\n",
    "from optimizers import *\n",
    "from model_manager import *\n",
    "from losses import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/zeus/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/fa97f6e7cb1a59073dff9e6b13e2715cf7475ac9/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/zeus/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/fa97f6e7cb1a59073dff9e6b13e2715cf7475ac9/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/zeus/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/fa97f6e7cb1a59073dff9e6b13e2715cf7475ac9/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/zeus/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/fa97f6e7cb1a59073dff9e6b13e2715cf7475ac9/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2088,  102],\n",
       "        [ 101, 7592,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"hello world\",\"hello\"], return_tensors=\"pt\",padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CodeSearchDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 config: DictConfig,):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Args:\n",
    "            file_paths: A list of paths to JSONL files.\n",
    "            tokenizer: A CodeSearchTokenizer instance.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.data = self._load_data_from_jsonl(self.config.file_paths)\n",
    "\n",
    "    def _load_data_from_jsonl(self, file_paths: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Loads data from one or more JSONL files into a pandas DataFrame.\"\"\"\n",
    "        all_data = []\n",
    "        for file_path in file_paths:\n",
    "            try:\n",
    "                data = pd.read_json(file_path, lines=True)\n",
    "                all_data.append(data)\n",
    "            except ValueError:\n",
    "                print(f\"Warning: File wans't read: {file_path}\")\n",
    "                continue\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx: The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the tokenized inputs.\n",
    "        \"\"\"\n",
    "        item = self.data.iloc[idx]\n",
    "        query = item['query']\n",
    "        code = item['code']\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"code\": code\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"/teamspace/studios/this_studio/semantic_code_search/conf/modeling.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CodeSearchDataset(config=config.data.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ['get the index of an item in a list.',\n",
       "  'performs linear regression using glm.',\n",
       "  'returns strings that match a regular expression.',\n",
       "  'changes the color of a string.',\n",
       "  'plots linear regression on an existing plot.',\n",
       "  'create a yes or no response.',\n",
       "  'checks if an XML element has a beginning property.',\n",
       "  'concatenate columns in a SQL query.'],\n",
       " 'code': ['def get_index(lst, item):\\n    return lst.index(item)\\n```',\n",
       "  'def glm_linear_regression(X, y):\\n    import statsmodels.api as sm\\n    X = sm.add_constant(X)\\n    model = sm.OLS(y, X).fit()\\n    return model\\n```',\n",
       "  'def filter_strings(lst, pattern):\\n    import re\\n    return [s for s in lst if re.match(pattern, s)]\\n```',\n",
       "  'def change_string_color(s, color):\\n    return f\"\\\\033[{color}m{s}\\\\033[0m\"\\n```',\n",
       "  \"def plot_linear_regression(ax, x, y):\\n    from numpy import polyfit, poly1d\\n    coefficients = polyfit(x, y, 1)\\n    linear_func = poly1d(coefficients)\\n    ax.plot(x, linear_func(x), color='red')\\n```\",\n",
       "  'def yes_no_response(condition):\\n    return \"yes\" if condition else \"no\"\\n```',\n",
       "  \"def has_beginning_property(element):\\n    return 'beginning' in element.attrib\\n```\",\n",
       "  'def concatenate_columns(cursor, table, col1, col2):\\n    cursor.execute(f\"SELECT CONCAT({col1}, {col2}) FROM {table}\")\\n    return cursor.fetchall()\\n```']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collator(o)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/data/data_collator.py:590\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     return_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_tensors\n\u001b[0;32m--> 590\u001b[0m label_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m labels \u001b[39m=\u001b[39m [feature[label_name] \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features] \u001b[39mif\u001b[39;00m label_name \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39m# reconvert list[None] to None if necessary\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[39m# this might occur when we pass {..., \"labels\": None}\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "collator(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\n",
    "    \"q\" : [\"this is the first sentence\"],\n",
    "    \"k\" : [\"this is key\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collator(d)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/data/data_collator.py:590\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     return_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_tensors\n\u001b[0;32m--> 590\u001b[0m label_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m labels \u001b[39m=\u001b[39m [feature[label_name] \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features] \u001b[39mif\u001b[39;00m label_name \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39m# reconvert list[None] to None if necessary\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[39m# this might occur when we pass {..., \"labels\": None}\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "collator(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
