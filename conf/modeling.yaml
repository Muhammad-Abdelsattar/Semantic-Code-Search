model:
  model_id: "jinaai/jina-embeddings-v2-base-code"
  fine_tuning:
    full:
      layers: 2 #indicates the num of layers(last layers) to be trained. {0->no layers -1->all layers}
      train_embeddings: false
    peft:
      lora:
        config:
          task_type: "SEQ_CLS"
          inference_mode: False
          target_modules: ["q_proj", "v_proj", "k_proj"]
          r: 8
          lora_alpha: 32
          lora_dropout: 0.05
      prefix:
        config:
          task_type: "SEQ_CLS"
          num_virtual_tokens: 20
          inference_mode: False
          prefix_projection: True
